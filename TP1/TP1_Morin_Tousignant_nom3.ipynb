{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Physique numérique (PHY-3500) - TP1</center></h1>\n",
    "<hr>\n",
    "<br><br>\n",
    "\n",
    "**Membres de l'équipe**\n",
    "| Nom | NI |\n",
    "| --- | :---: |\n",
    "| Maxime Tousignant-Tremblay | 536 772 369 |\n",
    "| Philippe Morin | 536 776 382 |\n",
    "| Emilie Carré Smith| 111 235 839 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Optional, Callable\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "from scipy import integrate as intgr\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figureFormat = \"svg\",\n",
    "\n",
    "plt.style.use(\"LabReport.mplstyle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numéro 1\n",
    "\n",
    "*Trouvez analytiquement $\\pi(\\lambda|X = \\text{\\textbf{x}})$ et déduisez la valeur de $f(\\text{\\textbf{x}})$. Indice : trouvez une fonction $g(\\lambda)$ proportionnelle à la loi a posteriori, ce qui vous permettra de retrouver la même forme que la loi a priori $\\pi(\\lambda)$. Cette loi a priori $\\pi(\\lambda)$ est conjuguée à la vraisemblance $f(\\text{\\textbf{x}}|\\Lambda=\\lambda)$.*\n",
    "$$posteriori \\propto vraisemblance \\ (priori)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numéro 3\n",
    "\n",
    "*Écrivez une fonction permettant de lire les données des trois fichiers textes qui vous sont fournis.\n",
    "Chaque ligne d’un fichier est le temps en millisecondes auquel une impulsion a été mesurée.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadtxt(run : int) -> np.ndarray[np.float64]:\n",
    "    \"\"\"Extract the impulse time dataset from a given text file.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "        run\n",
    "            The dataset file number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        time\n",
    "            The numpy array containing the time, in milliseconds,\n",
    "            of a mesured impulse.\n",
    "    \"\"\"\n",
    "    t = np.loadtxt(f\"activite_temps_{run}.txt\")\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numéro 4\n",
    "\n",
    "*En inférence bayésienne, il n’est généralement pas possible d’évaluer analytiquement $f(\\text{\\textbf{x}})$ et l’équation (5). En posant que $\\alpha=2$ et $\\beta=1/4$, évaluez numériquement $f(\\text{\\textbf{x}})$ et $\\hat{\\lambda}$ pour chaque série de données $x$ en utilisant la méthode de Simpson et la méthode de Romberg. Considérez que $\\lambda=200$ est suffisamment grand dans les bornes d’intégration.*\n",
    "\n",
    "D'après le théorème de Bayes, on a:\n",
    "$$\\pi(\\lambda|X=\\text{\\textbf{x}}) = \\frac{f(\\text{\\textbf{x}}|\\Lambda=\\lambda)\\pi(\\lambda)}{f(\\text{\\textbf{x}})} = \\frac{f(\\text{\\textbf{x}}|\\Lambda=\\lambda)\\pi(\\lambda)}{\\int f(\\text{\\textbf{x}}|\\Lambda=\\lambda)\\pi(\\lambda)d\\lambda}\\ .$$\n",
    "\n",
    "On suppose que la valeur *a priori* $\\pi(\\lambda)$ obéit à une loi Gamma de paramètres $\\alpha$ et $\\beta$ telle que:\n",
    "$$\\pi(\\lambda) = \\frac{\\lambda^{\\alpha-1}e^{-\\beta\\lambda}\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\ .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition d'une fonction d'intégration par la méthode de Romberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaymat(func: Callable, a: int, b: int, R: np.ndarray[np.float64]):\n",
    "    \"\"\"Display the Romberg result matrix for easier debugging.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        func\n",
    "            The function that has been integrated.\n",
    "        a\n",
    "            The lower limit of integration.\n",
    "        b\n",
    "            The upper limit of integration.\n",
    "        R\n",
    "            The Romberg result matrix.\n",
    "    \"\"\"\n",
    "    # Initialize matrix indexes\n",
    "    i = j = 0\n",
    "    _len = len(R)\n",
    "\n",
    "    # Compute the number of function evaluations\n",
    "    nbf = 2**(_len - 1) + 1\n",
    "\n",
    "    print(f\"Romberg integration of {repr(func)} from {[a, b]} \\n\")\n",
    "    print(f\"Steps \\t StepSize Results\")\n",
    "    idx = np.arange(_len)\n",
    "    stepsize = (b - a) / 2**idx\n",
    "    for i in idx:\n",
    "        print(\"%d \\t %d \\t \" % (2**i, stepsize[i]), end=\" \")\n",
    "        for j in range(i+1):\n",
    "            print(\"%.3e\" % (R[i, j]), end=\" \")\n",
    "        print(\"\")\n",
    "    print(f\"\\nThe final result is: {R[i, j]} after {nbf} function evaluations.\")\n",
    "\n",
    "\n",
    "def romb(\n",
    "    f: Callable,\n",
    "    a: int,\n",
    "    b: int,\n",
    "    n: int = 10,\n",
    "    show: bool = False,\n",
    "    **kwargs,\n",
    ") -> np.float64:\n",
    "    \"\"\"Compute the integral of 'f' from 'a' to 'b' using Romberg integration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        f\n",
    "            The function to integrate.\n",
    "        a\n",
    "            The lower limit of integration. \n",
    "        b\n",
    "            The upper limit of integration.\n",
    "        n\n",
    "            The number of iterations to use.\n",
    "        show\n",
    "            Whether to print the results. Defaults to False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        approx\n",
    "            The approximate value of the integral.\n",
    "    \"\"\"\n",
    "    # Initialize the Romberg integration table\n",
    "    R = np.empty((n, n))\n",
    "\n",
    "    # Configure function f to pass extra arguments\n",
    "    f = partial(f, **kwargs)\n",
    "\n",
    "    # Compute the trapezoidal rule for the first column\n",
    "    h = b - a\n",
    "    R[0, 0] = 0.5 * h * (f(a) + f(b))\n",
    "\n",
    "    # Iterate to refine the approximation\n",
    "    idx = np.arange(1, n)\n",
    "    h *= 0.5**idx\n",
    "    for i in idx:\n",
    "        k = np.arange(1, 2**i, 2)\n",
    "        sum_f = f(a + k * h[i-1]).sum()\n",
    "        R[i, 0] = 0.5 * R[i-1, 0] + sum_f * h[i-1]\n",
    "\n",
    "        # Compute the rest of the column using Richardson extrapolation\n",
    "        for j in range(1, i+1):\n",
    "            R[i, j] = R[i, j-1] + (R[i, j-1] - R[i-1, j-1]) / (4**j - 1)\n",
    "\n",
    "    # Send table to display function for debuging purposes if specified\n",
    "    if show is True:\n",
    "        displaymat(f, a, b, R)\n",
    "\n",
    "    approx = R[n-1, n-1]\n",
    "    return approx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résolution du problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for dataset 0:\n",
      "Simpson: f(x) ≈ 3.815472911396959e+48, λ_hat ≈ 8.879626693245141\n",
      "Romberg: f(x) ≈ 3.8146591982534476e+48, λ_hat ≈ 8.879362405236945 \n",
      "\n",
      "Results for dataset 1:\n",
      "Simpson: f(x) ≈ 2.283316152735809e+85, λ_hat ≈ 21.070284448840063\n",
      "Romberg: f(x) ≈ 2.2833160835509094e+85, λ_hat ≈ 21.0702837622328 \n",
      "\n",
      "Results for dataset 2:\n",
      "Simpson: f(x) ≈ 4.12526757520123e+105, λ_hat ≈ 33.91355504031561\n",
      "Romberg: f(x) ≈ 4.1252675874532674e+105, λ_hat ≈ 33.91355487153926 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem constants\n",
    "ALPHA = 2\n",
    "BETA = 0.25\n",
    "\n",
    "\n",
    "@np.vectorize(excluded=[\"xdata\", \"fx\"])\n",
    "def bayesian_inf(\n",
    "    lamb: np.float64,\n",
    "    xdata: np.ndarray[np.float64],\n",
    "    fx: Optional[np.float64] = None,\n",
    ") -> np.ndarray[np.float64]:\n",
    "    \"\"\"Compute the normalized or unnormalized posterior values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        lamb\n",
    "            The rate parameter of the exponential distribution.\n",
    "        xdata\n",
    "            The time difference dataset of the distribution.\n",
    "        fx\n",
    "            The 'evidence' or 'Marginal likelihood' of the distribution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        post\n",
    "            The normalized posterior values if 'fx' is given, the unnormalized\n",
    "            value otherwise.\n",
    "    \"\"\"\n",
    "    # Compute the prior\n",
    "    prior = st.gamma.pdf(lamb, ALPHA, scale=1/BETA)\n",
    "\n",
    "    # Compute the liklihood\n",
    "    likelihood = np.prod(lamb * np.exp(-lamb * xdata))\n",
    "\n",
    "    # Compute the distribution's posterior\n",
    "    post = likelihood * prior\n",
    "    if fx is not None:\n",
    "        post *= lamb / fx\n",
    "    return post\n",
    "\n",
    "\n",
    "def fx_simp(\n",
    "    data: int,\n",
    "    a: int,\n",
    "    b: int,\n",
    "    n: Optional[int] = None,\n",
    ") -> np.float64:\n",
    "    \"\"\"Compute f(x) and MLE using Simpson's integration rule.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        data\n",
    "            The dataset to integrate using Simpson's rule.\n",
    "        a\n",
    "            The lower limit of integration.\n",
    "        b\n",
    "            The upper limit of integration.\n",
    "        n\n",
    "            The number of samples between the integration limits. Defaults to\n",
    "            50, the default value of the 'linspace' function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        fx\n",
    "            The 'evidence' or 'Marginal likelihood' of the distribution.\n",
    "        lamb_hat\n",
    "            The Maximum Likelihood Estimate (MLE) for lambda.\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = b + 100\n",
    "    _lamb = np.linspace(a, b, n)\n",
    "\n",
    "    fx = intgr.simpson(bayesian_inf(_lamb, xdata=data), x=_lamb)\n",
    "    lamb_hat = intgr.simpson(bayesian_inf(_lamb, xdata=data, fx=fx), x=_lamb)\n",
    "    return fx, lamb_hat\n",
    "\n",
    "\n",
    "def fx_romb(\n",
    "    data: np.ndarray[np.float64],\n",
    "    a: int,\n",
    "    b: int,\n",
    "    n: Optional[int] = 10,\n",
    ") -> tuple[np.float64 | float]:\n",
    "    \"\"\"Compute f(x) and MLE with Romberg's integration rule.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        data\n",
    "            The dataset to integrate using Simpson's rule.\n",
    "        a\n",
    "            The lower limit of integration.\n",
    "        b\n",
    "            The upper limit of integration.\n",
    "        n\n",
    "            The number of iterations to use.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        fx\n",
    "            The 'evidence' or 'Marginal likelihood' of the distribution.\n",
    "        lamb_hat\n",
    "            The Maximum Likelihood Estimate (MLE) for lambda.\n",
    "    \"\"\"\n",
    "    fx = romb(bayesian_inf, a, b, xdata=data, n=n)\n",
    "    lamb_hat = romb(bayesian_inf, a, b, xdata=data, n=n, fx=fx)\n",
    "    return fx, lamb_hat\n",
    "\n",
    "\n",
    "for k in range(3):\n",
    "    tdata = np.ediff1d(loadtxt(k))\n",
    "    _simps = fx_simp(tdata, 0, 200, 1000)\n",
    "    _romb = fx_romb(tdata, 0, 200, 10)\n",
    "    print(f\"Results for dataset {k}:\")\n",
    "    print(f\"Simpson: f(x) \\u2248 {_simps[0]}, \\u03BB_hat \\u2248 {_simps[1]}\")\n",
    "    print(f\"Romberg: f(x) \\u2248 {_romb[0]}, \\u03BB_hat \\u2248 {_romb[1]} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numéro 5\n",
    "\n",
    "En comparant à votre solution analytique, tracez l’erreur sur $f(\\text{\\textbf{x}})$ et $\\hat{\\lambda}$ engendrée par vos deux méthodes d’intégration en fonction du nombre de tranches pour le jeux de données de votre choix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numéro 6\n",
    "\n",
    "Quels sont les défis reliés à l’intégration numérique de l’évidence $f(\\text{\\textbf{x}})$ en inférence bayésienne ?\n",
    "<br><br>\n",
    "\n",
    "blabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numéro 7\n",
    "\n",
    "Tracez un histogramme des fréquences relatives des écarts entre les impulsions. Tracez également la loi du modèle a priori $f(x_i|\\Lambda = \\lambda_0)$ et celle ajustée $f(x_i|\\Lambda = \\hat{\\lambda})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numéro 8\n",
    "\n",
    "Avec vos connaissances sur le processus de Poisson et l’inférence bayésienne, que pouvez-vous conclure du comportement de chaque neurone grâce à vos résultats ? Les processus sont-ils poissonien dans tous les cas ?\n",
    "<br><br>\n",
    "\n",
    "blabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Références\n",
    "\n",
    "blabla"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
